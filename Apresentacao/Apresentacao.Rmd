---
title: "Forest Fires in Portugal"
author: Jo√£o Teixeira - up200705307, Nuno Peixoto - up200804621
date: "25-01-2015"
output:
  beamer_presentation:
    toc: true
theme: Antibes
---

```{r imports, echo=FALSE, results='hide', comment=FALSE, message=FALSE}
setwd(dir = "/home/joao/Documents/Data-Mining")
source('Functions.R')
train_data <- read.csv("data/train.csv", head=T,  na.strings=c("?"))
```

```{r trim_data, echo=FALSE}
nanration <- gain.ratio(formula =  TotalBurntArea ~ ., train_data)
nanration$attribute <- rownames(nanration)
nanration <- nanration[order(nanration$attr_importance, decreasing =T ),]
nanration <- nanration[is.nan(nanration$attr_importance),]
rownames(nanration) <- 1:nrow(nanration)
att_names <- nanration$attribute
new_train_data <- train_data[,!(names(train_data) %in% att_names)]
```


## Introduction

* Monitoring and forecasting forest fires in Portugal;

* The several variables may influence the burnt area;

* In 2003, Portugal faced the worst forest fire losing 8.6% of of the total area;

* Elevation, slope or density are some of the specifications of the data set; 

**Objective** : Explore and predicte the data of the forest.


## Exploratory analysis of the data

* Global Summary
* Main Variables
* Target Variable

## Global Summary

* Number of Columns: `r ncol(train_data)`.
* Number of Rows: `r nrow(train_data)`.
* Number of Data: `r ncol(train_data)*nrow(train_data)`.
* Target Value: 1 (TotalBurntArea) - Numeric variable.
* Number of Unknown Values: `r sum(apply(train_data, 1, function(x){any(is.na(x))}))`.

## Global Summary (cont.)

**Climate Variables** - The climatic conditions may affect the probability of a fire to occur;

**Landscape Variables** - The landscape has been extensively associated with fire occurrence;

**Socio-economic Variables** - Human have impact in historical fire patterns;

**Topographic Variables** - The topographic features may influence the fire ignitions;


## Main Variables 

In the following table we have the **TOP5** main variables: 

```{r gain_ratio, echo=FALSE}
a <- gain.ratio(formula =  TotalBurntArea ~ ., train_data)
a$attribute <- rownames(a)
a <- head(a[order(a$attr_importance, decreasing =T ),],5)
rownames(a) <- 1:nrow(a)
pander(a, style = "grid")
```

## Main Variables (Number of outliers)
```{r top5_vars, echo=FALSE, comment=NA}
att <- a$attribute
```

```{r call_functions, echo=FALSE, results='hide'}
nouts <- out_tax(train_data,att)
stand_dev <- stand_dev(train_data,att)
```

* ELEV_MAX: `r nouts[1]`

* Bio1: `r nouts[2]`

* ELEV_MEAN: `r nouts[3]`

* Bio7: `r nouts[4]`

* DensPop01: `r nouts[5]`


## Main Variables (Standard Deviation)
* ELEV_MAX: `r stand_dev[1]`

* Bio1: `r stand_dev[2]`

* ELEV_MEAN: `r stand_dev[3]`

* Bio7: `r stand_dev[4]`

* DensPop01: `r stand_dev[5]`

## Target Variable

```{r tv_sum, echo=FALSE, comment=NA}
tmp <-summary(train_data["TotalBurntArea"])
prc <- summaryToDataFrame(tmp)
pander(prc, style="grid")
```

## Target Variable (Number of outliers)
```{r tv_out, echo=FALSE}
outs <- out_tax(train_data,c("TotalBurntArea"))
```

* TotalBurntArea: `r outs[1]`

We can see that more than 10% of the total burnt area values are considered outliers.

## Target Variable (Total Area vs. Total Burnt Area)
```{r times_burnt, echo=FALSE}
tmp<-train_data[train_data$TA<train_data$TotalBurntArea,c("TA","TotalBurntArea")]
ggplot(tmp, aes(factor(round(tmp$TotalBurntArea/tmp$TA)))) + geom_bar() + xlab("Times Burnt") + ggtitle("Times Total Area Burnt")
```


## Data Pre-Processing

* Remove None importance Variables
* Normalizing Value

## Remove None importance Variables

```{r non_importance_vars, echo=FALSE}
nanration <- gain.ratio(formula =  TotalBurntArea ~ ., train_data)
nanration$attribute <- rownames(nanration)
nanration <- nanration[order(nanration$attr_importance, decreasing =T ),]
nanration <- nanration[is.nan(nanration$attr_importance),]
rownames(nanration) <- 1:nrow(nanration)
pander(nanration, style = "grid")
```


```{r remove_ration, echo=FALSE, results='hide'}
data <- ncol(train_data)*nrow(train_data)
rmdata <- nrow(train_data)*(ncol(train_data)-nrow(nanration))
perc <- round(((data-rmdata)/(data))*100,2)
```

* This pre-processing that does not prejudice the information analysis;
* We reduce about `r perc`% of the total data.

## Normalizing Value

* Data normalization pre-processing we will use for the analisys;

```{r normalize, echo=FALSE}
norm.train_data <- scale(train_data[,])
colnames(train_data) <- colnames(train_data)
norm.train_data <- data.frame(norm.train_data)
```

```{r view_norm_data, echo=FALSE}
head(train_data[,c(1:6)], 3)
head(norm.train_data[,c(1:6)], 3)
```

## Predictive Models

In order to find the best regression model that can predict the target variable of the test data set with less error, we analysed the following forecasting models:

* Multiple Linear Regression
* Regression Trees
* K-Nearest Neighbors (KNNs)
* Support Vector Machines (SVMs)
* Artificial Neural Networks (ANNs)
* Random Forest (Ensembles)

## Model comparison

The metric evaluation to be considered for these forecasts is the MAE - Mean Absolute Error. We use a
cross validation method with 2 repetitions of 3 folds.

To evaluate the models we will use the performanceEstimation package that provides a set of functions
and arguments that allow us to change the values of parameters in order to check the best fit for an specific
model.

## Model performance

| **Model**                        | **MAE ERROR** | **Parameters**                                                                           |
| -------------------------------- |:-------------:| -----------------------------------------------------------------------------------------|
| SVM (ksvm)                       |1732.284       |  **epsilon**:1e-09, **C**:1, **kernel**:rbfdot                                           |
| SVM                              |1762.223       |  **cost**:1, **gamma**:0.01                                                              |
| k-Nearest Neighbors              |1916.375       |   **scale**:TRUE, **k**:11, **distance**:1, **kernel**:triangular                        |
| Multiple Linear Regression       |2310.785       |   Default Parameters                                                                     |
| ANN                              |2393.626       |   **size**:2, **maxit**:200, **decay**:0.1, **scale**:TRUE, **trace**:FALSE, **linout**:1|
| Random Forest                    |2393.626       | **ntree**:500, **nodesize**:5, **corr.bias**:FALSE, **mtry**:3                           |
| Regression Trees                 |2802.628       |   **se**:1, **minsplit**:15                                                              |

## Models Plot

```{r total, echo=FALSE, warning=FALSE, comment=FALSE, comment=FALSE, message=FALSE, results='hide', dpi=100}
total <- performanceEstimation(
  PredTask(TotalBurntArea ~ ., new_train_data),
  c(workflowVariants(learner="lm", pre="centralImp",post="onlyPos"),
    workflowVariants(learner="rpartXse",
                     learner.pars=list(se=1, minsplit=20)),
    workflowVariants(learner="train.kknn",
                     learner.pars=list(scale=T, k=13, distance=1, kernel="epanechnikov")),
    workflowVariants(learner="svm",
                     learner.pars=list(cost=1, gamma=0.01)),
    workflowVariants(learner="ksvm",
                     learner.pars=list(epsilon=10^-9, C=1, kernel="rbfdot")),
    workflowVariants(learner="nnet",
                     learner.pars=list(size=4, maxit=300, decay=0.4, scale=T, trace=F, linout=1)),
    workflowVariants(learner="randomForest",
                     learner.pars=list(ntree=250, nodesize=5, corr.bias=F, mtry=9))),
  EstimationTask(metrics="mae",method=CV(nReps=1,nFolds=2)))

plot(total, ylab="Model", xlab="MAE Results")
```

## Conclusion

**Best performance models**
  * **SVM** (ksvm)
    * MAE error: 1732.284
    
  * **SVM**
    * MAE error: 1762.223
    
  * **k-Nearest Neighbors**
    * MAE error: 1916.375

## Clustering

The following clustering methods were used to try to find different groups of observations present in the data set:

* Clustering Large Applications (CLARA)
* Partitioning Around Medoids (PAM)
* Hierarchical Clustering
* K-Means Clustering

## Clustering results

Using a R script with the help of the silhouette function we could find the best number of clusters for each used method 

| CLARA   |         |PAM      |         |
|---------|---------|---------|---------|
|nClusters|SilhCo   |nClusters|SilhCo   |
|2        |0.7144933|2        |0.7336859|
|4        |0.6361579|3        |0.6187632|
|3        |0.6243904|4        |0.4812423|
|5        |0.3102661|5        |0.4318594|
|10       |0.2789919|6        |0.3595906|
|9        |0.2749504|7        |0.3234947|
|6        |0.2645142|9        |0.2750479|
|7        |0.2329236|8        |0.2561567|
|8        |0.2286001|10       |0.2560370|

## Clustering results (cont.)

|hclust   |          |kmeans   |         |
|---------|----------|---------|---------|
|nClusters|SilhCo    |nClusters|SilhCo   | 
|2        |0.55027091|2        |0.7791398|
|3        |0.32391734|3        |0.6993844|
|5        |0.17051099|4        |0.6888222|
|4        |0.16893921|5        |0.5839630|
|6        |0.09489308|6        |0.5492905|
|7        |0.09160570|7        |0.3886676|
|8        |0.08740959|8        |0.3868419|
|10       |0.08135908|10       |0.3321750|
|9        |0.07454503|9        |0.3175380|

## Silhouette Plot

```{r, echo=FALSE}
k2 = kmeans(new_train_data[,-73], centers=2, iter.max=300)
s = silhouette(k2$cluster,dist(new_train_data[,-73]))
plot(s)
```