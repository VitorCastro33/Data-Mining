
We used the following script to find the best k (from 2 to 10) value for clustering the data using the kmeans method:
library(cluster)
```{r}
set.seed(1234)
d = dist(new_train_data[,-73])
avgS = c()
for(k in 2:10){
  cl = kmeans(new_train_data[,-73],centers=k,iter.max=300)
  s = silhouette(cl$cluster,d)
  avgS = c(avgS,mean(s[,3]))
}
```

The best k is given by the silhouette coefficient closer to 1: 

```{r, echo=FALSE}
res = data.frame(nClusters=2:10,SilhCo=avgS)
res[order(res$SilhCo,decreasing=TRUE),]
```

If we plot the silhouette of the clustering using kmeans with the k=2 centers, we can see that we only get a very small percentage of cases in one of the clusters, and all the remaining cases in the other, this means that the distance of observations in the data set is very small.

```{r, echo=FALSE}
k2 = kmeans(new_train_data[,-73], centers=2, iter.max=300)
s = silhouette(k2$cluster,dist(new_train_data[,-73]))
plot(s)
```